{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f2d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =pd.read_csv(\"C:/Users/HP/workspace/Real Estate Prediction Project/dataset/Bengaluru_House_Data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c4fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(\"area_type\")['area_type'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b60425",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ec4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping columns that are essentially not useful to determining our house price\n",
    "\n",
    "data1 = data.drop(['area_type', 'society', 'balcony', 'availability'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling the na values\n",
    "data2 = data1.dropna()\n",
    "data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93634e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the size column and clearing and tokenising it\n",
    "view = data2['size'].unique()\n",
    "\n",
    "#creating a new tokenized size column\n",
    "data2['bhk'] = data2['size'].apply(lambda x: int(x.split(\" \")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dae6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the total_sqft column\n",
    "vi = data2.total_sqft.unique()\n",
    "# defining a function to convert the range values in the total_square column\n",
    "\n",
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83f6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[~data2[\"total_sqft\"].apply(is_float)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228442b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function  to convert the range values to float\n",
    "def convert_sqft_to_num(x):\n",
    "    token = x.split(\"-\")\n",
    "    if len(token) == 2:\n",
    "        return (float(token[0])+float(token[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a96f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.copy()\n",
    "data3['total_sqft'] = data3['total_sqft'].apply(convert_sqft_to_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91f6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering and dimensionality reduction \n",
    "#creating price per square fit column\n",
    "\n",
    "data4 = data3.copy()\n",
    "data4['price_per_sqft'] = data4['price']*100000/data4['total_sqft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79455a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the location column\n",
    "data4.location == data4.location.apply(lambda x: x.strip())\n",
    "location_stats = data4['location'].value_counts(ascending=False)\n",
    "\n",
    "location_stats1 = data4.groupby('location')['location'].agg('count').sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4724695",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(location_stats[location_stats<=10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f320bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "location_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa7e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting location that are less that 10 to other\n",
    "data4.location = data4.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)\n",
    "len(data4.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c81043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier detection and remover\n",
    "#checcking the data points where the sqft is less than 300(threshold)\n",
    "check = data4[data4.total_sqft/data4.bhk<300]\n",
    "\n",
    "#removing the outliers\n",
    "data5 = data4[~(data4.total_sqft/data4.bhk<300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb68197",
   "metadata": {},
   "outputs": [],
   "source": [
    "data5.price_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing a function that can remove extreme cases of high price_per_sqft per location\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        sd = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-sd)) & (subdf.price_per_sqft<=(m+sd))]\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n",
    "    return df_out\n",
    "    \n",
    "data6 = remove_pps_outliers(data5)\n",
    "data6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for data visualisation of the 2&3 bedroom case senerior\n",
    "\n",
    "def plot_scatter_chart(df, location):\n",
    "    bhk2 = df[(df.location==location) & (df.bhk==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.bhk==3)]\n",
    "    plt.rcParams['figure.figsize'] = (15, 10)\n",
    "    plt.scatter(bhk2.total_sqft, bhk2.price, color='blue', label = '2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft, bhk3.price, marker='+', color='green', label = '3 BHK', s=50)\n",
    "    plt.xlabel(\"Total square Feet Area\")\n",
    "    plt.ylabel(\"Price Per Square Feet\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_scatter_chart(data6, \"Rajaji Nagar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3676ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fnction to remove those 2 BHK apartment whose price_per_sqft is less than\n",
    "#mean price price_per_sqft of 1bHK apartment\n",
    "\n",
    "def remove_bhk_outlier(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft), \n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        for bhk, bhk_df in location_df.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices, axis = 'index')\n",
    "            \n",
    "data7 = remove_bhk_outlier(data6)\n",
    "data7.shape\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0795e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(data7, \"Hebbal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ploting  a histogram to see hoow many apartment are there per_sqft Area\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.hist(data7.price_per_sqft, rwidth=0.8)\n",
    "plt.xlabel('Price Per Square Feet')\n",
    "plt.ylabel('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d55181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the outliers on the bath columns. every datapoint having 2bathroom more than bedbroom is categorized \n",
    "# as an outlier\n",
    "\n",
    "data8 = data7[data7.bath < data7.bhk+2]\n",
    "data8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1824c5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#droping the unneccessary features like price_per_sqft and size\n",
    "\n",
    "data9 = data8.drop(['size', 'price_per_sqft'], axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4a56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a machine learning model for price prediction \n",
    "#using onehot encoding on the location column\n",
    "\n",
    "dummies = pd.get_dummies(data9.location)\n",
    "\n",
    "#concatingn the dummies + the original data\n",
    "data10 = pd.concat([data9, dummies.drop('other', axis = 'columns')], axis = 'columns')\n",
    "\n",
    "data11 = data10.drop('location', axis= 'columns')\n",
    "data11.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfe8585",
   "metadata": {},
   "source": [
    "Building the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d758c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating x and y datapoint of training the machine learning model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "X = data11.drop('price', axis ='columns')\n",
    "y = data11.price\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fd4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using kfold validation\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size = 0.2, random_state = 0)\n",
    "cross_val_score(lr_model, X, y, cv=cv )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003c4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using gridsearchcv\n",
    "#hyper-parameter tunning\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def find_best_model_using_gridsearchcv(x,y):\n",
    "    algos = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        \n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "            \n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion': ['mse', 'friedman_mse'],\n",
    "                'splitter': ['best', 'random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score = False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99752dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the predict function\n",
    "\n",
    "def predict_price(location, sqft, bath, bhk):\n",
    "    loc_index = np.where(X.columns==location)[0]\n",
    "    \n",
    "    x=np.zeros(len(X.columns))\n",
    "    x[0]=sqft\n",
    "    x[1]=bath\n",
    "    x[2]=bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] =  1\n",
    "    return lr_model.predict([x])[0]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fed0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('1st phase JP Nagar', 1000, 3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d402afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar', 1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the model to the pickle file\n",
    "import pickle\n",
    "with open ('banglore_home_price_model.pickle', 'wb') as f:\n",
    "    pickle.dump(lr_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8b4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting the columns labels which will be usefull for prediction\n",
    "\n",
    "import json\n",
    "columns = {\n",
    "    'data_columns': [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\", \"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
